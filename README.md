# ML-with-House-Price-Prediction-Dataset
ğŸ  House Price Prediction using Machine Learning
ğŸ“Œ Project Overview

This project focuses on predicting house prices using machine learning techniques.
The goal is to analyze housing features, preprocess the data, and build a regression model that can accurately predict house prices.

The project uses XGBoost Regressor, a powerful gradient boosting algorithm, and evaluates model performance using RÂ² Score and Mean Absolute Error (MAE).

ğŸ“‚ Dataset

Dataset Name: Housing Dataset

File: Housing.csv

Target Variable: price

Key Features

Area

Bedrooms

Bathrooms

Stories

Parking

Furnishing status

Amenities such as air conditioning, basement, guest room, etc.

ğŸ› ï¸ Technologies & Libraries Used

Python

Pandas

NumPy

Matplotlib

Seaborn

Scikit-learn

XGBoost

ğŸ” Project Workflow
1ï¸âƒ£ Data Loading

Loaded the dataset using Pandas

Inspected shape, structure, and summary statistics

2ï¸âƒ£ Data Exploration & Analysis

Checked for missing values

Generated descriptive statistics

Visualized correlations using a heatmap to understand feature relationships

3ï¸âƒ£ Data Preprocessing

Encoded categorical variables

Removed unnecessary columns

Prepared feature matrix (X) and target vector (y)

Split data into training and testing sets

ğŸ¤– Model Building

Used XGBoost Regressor

Trained the model on training data

Evaluated performance on both training and test datasets

ğŸ“Š Model Evaluation
Metrics Used

RÂ² Score

Mean Absolute Error (MAE)

Observations

Training performance was very high, indicating strong learning

Test performance was lower, indicating overfitting

Regularization and hyperparameter tuning were applied to reduce overfitting

ğŸ“ˆ Results
Dataset	RÂ² Score	MAE
Training Data	~0.99	Low
Test Data	~0.59	~1,053,105

The gap between training and testing scores indicates overfitting, which is common with powerful models like XGBoost.

ğŸš€ Improvements & Future Work

Hyperparameter tuning using GridSearchCV

Feature engineering

Log transformation of target variable

Cross-validation

Outlier handling

Trying alternative models (Random Forest, Gradient Boosting)

ğŸ“Œ Conclusion

This project demonstrates a complete machine learning pipeline for house price prediction.
While the model performs well on training data, further tuning is required to improve generalization on unseen data.
